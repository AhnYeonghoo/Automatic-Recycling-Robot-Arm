{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNXEEHkN8mqTWLi19Gmb0x2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhnYeonghoo/Plastic-self-classification-system-using-deep-learning/blob/Machine-Learning/data_preprocessing1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%이 부분은 구글 드라이브 마운트 하는 부분이라 너가 로컬에서 할거면 바꿔서 해야해\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxNdKaKIr11v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "SugfjG172plj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%이건 갯수 맞춰보는거. 파일의 폴더 경로에 따라 바꿔서 해야해.\n",
        "\n",
        "# 두 개의 폴더 경로 설정\n",
        "LabeledData_path = '/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Labeled_Data_A1/A1'\n",
        "SourceData_path = '/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Source_Data_A1/A1'\n",
        "\n",
        "# 폴더 내 파일 개수 세기\n",
        "LabeledData_count = len([name for name in os.listdir(LabeledData_path) if os.path.isfile(os.path.join(LabeledData_path, name))])\n",
        "SourceData_count = len([name for name in os.listdir(SourceData_path) if os.path.isfile(os.path.join(SourceData_path, name))])\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"라벨링데이터의 파일 개수: {LabeledData_count}\")\n",
        "print(f\"원천데이터의 파일 개수: {SourceData_count}\")"
      ],
      "metadata": {
        "id": "ItKxuwHr2jKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "###########################################################\n",
        "# %% 이건 아까 말했던 갯수 손실난 부분 갯수 맞추는건데 너는 로컬에서 압축해제 하니까 손실 없을 수도 있어. 근데 손실 없더라도 혹시 모르니까 이 부분 꼭 돌려봐줘.\n",
        "###########################################################\n",
        "\n",
        "\n",
        "# 이미지와 라벨 파일 경로 설정 (구글 드라이브 내 경로로 설정)\n",
        "image_dir = \"/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Source_Data_A1/A1\"\n",
        "label_dir = \"/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Labeled_Data_A1/A1\"\n",
        "\n",
        "# 이미지와 라벨 파일 리스트 얻기\n",
        "image_files = set([os.path.splitext(f)[0] for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "label_files = set([os.path.splitext(f)[0] for f in os.listdir(label_dir) if f.endswith('.json')])\n",
        "\n",
        "# 이미지와 라벨 모두 있는 파일 리스트 찾기\n",
        "valid_files = image_files.intersection(label_files)\n",
        "\n",
        "# 이미지나 라벨만 있는 파일 리스트\n",
        "only_image_files = image_files - valid_files\n",
        "only_label_files = label_files - valid_files\n",
        "\n",
        "# 이미지나 라벨 중 하나만 있는 파일 삭제 (필요시)\n",
        "for file in only_image_files:\n",
        "    os.remove(os.path.join(image_dir, file + '.jpg'))\n",
        "\n",
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# %% 이게 제일 중요!!!!!! 이거랑 똑같은 코드가 뒤에 전처리 한 후에 또 쓰는거거든 근데 전처리를 하기 전에 라벨 데이터가 json파일이고 전처리 후에는 txt 파일이야. 그래서 이 주석 밑에 코드 돌릴때 json인지 txt인지 잘 보고 돌려야해.\n",
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "for file in only_label_files:\n",
        "    os.remove(os.path.join(label_dir, file + '.json'))\n",
        "\n",
        "\n",
        "print(f\"총 {len(valid_files)}개의 유효한 이미지와 라벨 파일이 있습니다.\")\n"
      ],
      "metadata": {
        "id": "leCiocATFvZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "#######################\n",
        "# 데이터 전처리해서 output_dir에 저장하는거. 이제 여기서는 이미지 데이터, 라벨 데이터가 하나의 폴더에 합쳐질거야.\n",
        "#######################\n",
        "# 경로 설정\n",
        "label_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Labeled_Data_A1/A1'\n",
        "image_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Source_Data_A1/A1'\n",
        "output_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Validation/A1/Output_Data_A1'  # 이미지와 라벨 파일 저장 경로\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# YOLO에서 사용할 고정된 크기\n",
        "TARGET_SIZE = 640\n",
        "\n",
        "# 클래스 매핑 (클래스 이름을 숫자 ID로 변환)\n",
        "class_mapping = {\n",
        "    \"c_5_02\": 0,\n",
        "    \"c_6\": 1,\n",
        "    \"c_5_01_01\": 2,\n",
        "    \"c_5_02_01\": 3,\n",
        "    \"c_6_01\": 4,\n",
        "    \"c_5_01\": 5\n",
        "}\n",
        "\n",
        "# 비율 유지하면서 이미지 축소 후 패딩 추가 함수\n",
        "def resize_with_padding(image, target_size):\n",
        "    h, w = image.shape[:2]\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w = int(w * scale)\n",
        "    new_h = int(h * scale)\n",
        "\n",
        "    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # 패딩 추가\n",
        "    delta_w = target_size - new_w\n",
        "    delta_h = target_size - new_h\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    return padded_image, scale, left, top\n",
        "\n",
        "# 바운딩 박스 좌표 변환 함수\n",
        "def convert_bbox(bbox, scale, left_pad, top_pad):\n",
        "    x_min = bbox['x'] * scale + left_pad\n",
        "    y_min = bbox['y'] * scale + top_pad\n",
        "    width = bbox['width'] * scale\n",
        "    height = bbox['height'] * scale\n",
        "\n",
        "    # YOLO 형식으로 변환 (x_center, y_center, width, height)\n",
        "    x_center = (x_min + width / 2) / TARGET_SIZE\n",
        "    y_center = (y_min + height / 2) / TARGET_SIZE\n",
        "    width /= TARGET_SIZE\n",
        "    height /= TARGET_SIZE\n",
        "\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "# 이미지와 JSON 파일을 처리하는 함수\n",
        "def process_image_and_label(image_path, label_path, output_dir):\n",
        "    # 이미지 읽기\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # 이미지 리사이즈 (비율 유지 + 패딩)\n",
        "    padded_image, scale, left_pad, top_pad = resize_with_padding(image, TARGET_SIZE)\n",
        "\n",
        "    # 출력 이미지 저장\n",
        "    image_name = os.path.basename(image_path)\n",
        "    output_image_path = os.path.join(output_dir, image_name)\n",
        "    cv2.imwrite(output_image_path, padded_image)\n",
        "\n",
        "    # JSON 파일 읽기\n",
        "    with open(label_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # YOLO 형식의 라벨 파일 생성\n",
        "    label_name = os.path.splitext(image_name)[0] + '.txt'\n",
        "    output_label_path = os.path.join(output_dir, label_name)\n",
        "\n",
        "    with open(output_label_path, 'w') as label_file:\n",
        "        for obj in data['objects']:\n",
        "            class_name = obj['class_name']  # 클래스 이름\n",
        "            bbox = obj['annotation']['coord']  # 바운딩 박스 좌표\n",
        "\n",
        "            # 바운딩 박스 좌표 변환\n",
        "            x_center, y_center, width, height = convert_bbox(bbox, scale, left_pad, top_pad)\n",
        "\n",
        "            # 클래스 ID 가져오기\n",
        "            class_id = class_mapping.get(class_name, -1)  # class_mapping에서 클래스 ID 찾기, 없으면 -1 반환\n",
        "            if class_id == -1:\n",
        "                print(f\"Warning: 클래스 '{class_name}'에 대한 매핑을 찾을 수 없습니다.\")\n",
        "                continue\n",
        "\n",
        "            # YOLO 형식으로 라벨 저장\n",
        "            label_file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "# 병렬 처리 함수\n",
        "def process_parallel():\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for label_file in os.listdir(label_dir):\n",
        "            if label_file.endswith('.json'):\n",
        "                image_file = label_file.replace('.json', '.jpg')\n",
        "                image_path = os.path.join(image_dir, image_file)\n",
        "                label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "                futures.append(executor.submit(process_image_and_label, image_path, label_path, output_dir))\n",
        "\n",
        "        # 완료된 작업 확인\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                future.result()  # 결과를 받아서 예외를 처리할 수 있음\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "\n",
        "# 병렬 처리 실행\n",
        "process_parallel()\n",
        "\n",
        "print(\"모든 이미지와 라벨이 병렬 처리되었습니다!\")\n"
      ],
      "metadata": {
        "id": "iFAG7cYwcQH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 새로운 출력 경로 설정 (유효한 데이터만 저장할 경로)\n",
        "new_output_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_val'\n",
        "output_dir = '/content/drive/MyDrive/yolo_training_A1/val'\n",
        "\n",
        "os.makedirs(new_output_dir, exist_ok=True)\n",
        "\n",
        "# 빈 라벨 및 해당 이미지 파일의 수를 확인하고, 유효한 데이터만 복사하는 함수\n",
        "def filter_and_copy_valid_data(output_dir, new_output_dir):\n",
        "    invalid_pairs_count = 0\n",
        "\n",
        "    for file_name in os.listdir(output_dir):\n",
        "        if file_name.endswith('.txt'):\n",
        "            file_path = os.path.join(output_dir, file_name)\n",
        "            if os.path.getsize(file_path) == 0:  # 파일 크기가 0이면 쓸모없는 데이터로 간주\n",
        "                # 같은 이름의 이미지 파일 경로\n",
        "                image_file = file_name.replace('.txt', '.jpg')\n",
        "                image_path = os.path.join(output_dir, image_file)\n",
        "\n",
        "                # 삭제할 데이터 쌍 개수 세기\n",
        "                invalid_pairs_count += 1\n",
        "                print(f\"빈 라벨 파일과 해당 이미지 파일 '{file_name}', '{image_file}'이 유효하지 않습니다.\")\n",
        "            else:\n",
        "                # 유효한 데이터만 새로운 디렉토리에 복사\n",
        "                valid_image_path = os.path.join(new_output_dir, file_name.replace('.txt', '.jpg'))\n",
        "                valid_label_path = os.path.join(new_output_dir, file_name)\n",
        "\n",
        "                # 이미지와 라벨 복사\n",
        "                shutil.copyfile(os.path.join(output_dir, file_name.replace('.txt', '.jpg')), valid_image_path)\n",
        "                shutil.copyfile(file_path, valid_label_path)\n",
        "\n",
        "    print(f\"총 {invalid_pairs_count}개의 쓸모없는 데이터 쌍이 발견되었습니다.\")\n",
        "    print(f\"유효한 데이터는 '{new_output_dir}'에 복사되었습니다.\")\n",
        "\n",
        "# 빈 파일 및 해당 이미지 파일 수 확인 및 유효한 데이터 복사\n",
        "filter_and_copy_valid_data(output_dir, new_output_dir)\n"
      ],
      "metadata": {
        "id": "3cXmemu9Qk0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y imgaug\n",
        "!pip install git+https://github.com/aleju/imgaug.git\n"
      ],
      "metadata": {
        "id": "krRzQbC0sj9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations"
      ],
      "metadata": {
        "id": "fyCUQMrD3sYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import json\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import albumentations as A\n",
        "\n",
        "# # 경로 설정\n",
        "# label_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_train'\n",
        "# image_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_train'\n",
        "# output_dir = '/content/drive/MyDrive/yolo_training_A1/Augmented_Output_Data_A1'\n",
        "\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# # 클래스 매핑\n",
        "# augment_classes = [0, 3]  # 증강할 클래스 (0과 3)\n",
        "# ignore_classes = [1, 2, 4, 5]  # 무시할 클래스\n",
        "\n",
        "# # 데이터 증강을 위한 Albumentations 설정 (확대/축소 없이 이동만 적용)\n",
        "# transform = A.Compose([\n",
        "#     A.HorizontalFlip(p=0.5),  # 50% 확률로 수평으로 뒤집기\n",
        "#     A.VerticalFlip(p=0.5),    # 50% 확률로 수직으로 뒤집기\n",
        "#     A.RandomBrightnessContrast(p=0.2),  # 20% 확률로 밝기와 대비 조정\n",
        "#     A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0, rotate_limit=0, p=0.5)  # 50% 확률로 이동만 적용\n",
        "# ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "# # 이미지와 라벨 파일을 처리하는 함수 (증강 포함)\n",
        "# def augment_data(image_path, label_path, output_dir, aug_count=1):\n",
        "#     # 이미지 읽기\n",
        "#     image = cv2.imread(image_path)\n",
        "#     if image is None:\n",
        "#         print(f\"Error: 이미지 '{image_path}'를 읽을 수 없습니다.\")\n",
        "#         return\n",
        "\n",
        "#     # 라벨 읽기\n",
        "#     label_name = os.path.basename(label_path)\n",
        "#     image_name = os.path.basename(image_path)\n",
        "\n",
        "#     # 증강된 이미지와 라벨의 이름에 접미사 추가\n",
        "#     output_image_name = f\"{os.path.splitext(image_name)[0]}_augmented{aug_count}.jpg\"\n",
        "#     output_label_name = f\"{os.path.splitext(label_name)[0]}_augmented{aug_count}.txt\"\n",
        "\n",
        "#     output_image_path = os.path.join(output_dir, output_image_name)\n",
        "#     output_label_path = os.path.join(output_dir, output_label_name)\n",
        "\n",
        "#     with open(label_path, 'r') as f:\n",
        "#         lines = f.readlines()\n",
        "\n",
        "#     bboxes = []\n",
        "#     class_labels = []\n",
        "\n",
        "#     # 바운딩 박스와 클래스 라벨을 읽어옴\n",
        "#     for line in lines:\n",
        "#         class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "#         class_id = int(class_id)\n",
        "\n",
        "#         # 증강할 클래스만 처리 (0과 3)\n",
        "#         if class_id in augment_classes:\n",
        "#             bboxes.append([x_center, y_center, width, height])\n",
        "#             class_labels.append(class_id)\n",
        "\n",
        "#     # 증강 실행 (바운딩 박스가 있을 때만)\n",
        "#     # if bboxes:\n",
        "#     #     augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "#     #     augmented_image = augmented['image']\n",
        "#     #     augmented_bboxes = augmented['bboxes']\n",
        "#     #     augmented_classes = augmented['class_labels']\n",
        "#     if bboxes:\n",
        "#         print(f\"증강 전 바운딩 박스: {bboxes}, 클래스 라벨: {class_labels}\")  # 추가된 디버깅 메시지\n",
        "\n",
        "#         # 클래스 라벨을 정수형으로 변환\n",
        "#         class_labels = [int(label) for label in class_labels]\n",
        "\n",
        "#         try:\n",
        "#             augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "#             augmented_image = augmented['image']\n",
        "#             augmented_bboxes = augmented['bboxes']\n",
        "#             augmented_classes = augmented['class_labels']\n",
        "\n",
        "#             # 증강된 이미지 저장\n",
        "#             cv2.imwrite(output_image_path, augmented_image)\n",
        "\n",
        "#             # 증강된 라벨 저장 (클래스 0과 3만 포함)\n",
        "#             with open(output_label_path, 'w') as label_file:\n",
        "#                 for class_id, bbox in zip(augmented_classes, augmented_bboxes):\n",
        "#                     label_file.write(f\"{class_id} {' '.join(map(str, bbox))}\\n\")\n",
        "#         except KeyError as ke:\n",
        "#             print(f\"KeyError 발생: {ke}, 클래스 라벨: {class_labels}, 바운딩 박스: {bboxes}\")\n",
        "#             return\n",
        "#         except Exception as e:\n",
        "#             print(f\"증강 중 다른 오류 발생: {type(e).__name__}, {e}\")\n",
        "#             return\n",
        "\n",
        "\n",
        "# # 멀티스레드를 사용한 병렬 처리 함수\n",
        "# def process_parallel():\n",
        "#     with ThreadPoolExecutor() as executor:\n",
        "#         futures = []\n",
        "#         aug_count = 1  # 증강 횟수를 카운트할 변수\n",
        "\n",
        "#         for label_file in os.listdir(label_dir):\n",
        "#             if label_file.endswith('.txt'):  # 라벨 파일이 있는 경우\n",
        "#                 image_file = label_file.replace('.txt', '.jpg')  # 동일한 이미지 파일명 찾기\n",
        "#                 image_path = os.path.join(image_dir, image_file)\n",
        "#                 label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "#                 # 병렬 처리에서 증강 횟수를 추적하면서 전달\n",
        "#                 futures.append(executor.submit(augment_data, image_path, label_path, output_dir, aug_count))\n",
        "#                 aug_count += 1  # 증강할 때마다 카운트를 증가시킴\n",
        "\n",
        "#         # 완료된 작업 확인\n",
        "#         for future in as_completed(futures):\n",
        "#             try:\n",
        "#                 future.result()  # 결과를 받아서 예외를 처리할 수 있음\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error 발생: {type(e).__name__}, {e}\")\n",
        "\n",
        "# # 병렬 처리 실행\n",
        "# process_parallel()\n",
        "\n",
        "# print(\"모든 데이터 증강이 완료되었습니다!\")\n"
      ],
      "metadata": {
        "id": "1qCr86gQRcDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import uuid  # 고유한 파일명을 위해 UUID 추가\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import albumentations as A\n",
        "\n",
        "label_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_train'\n",
        "image_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_train'\n",
        "output_dir = '/content/drive/MyDrive/yolo_training_A1/Augmented_Output_Data_A1'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "augment_classes = {0: 3, 3: 10}  # 클래스별 목표 증강 횟수 설정\n",
        "ignore_classes = [1, 2, 4, 5]  # 무시할 클래스\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0, rotate_limit=0, p=0.5)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "# 증강 데이터 생성 함수\n",
        "def augment_data(image_path, label_path, output_dir, class_id, target_count):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"[오류] 이미지 '{image_path}'를 읽을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # 증강할 클래스만 필터링\n",
        "    bboxes = []\n",
        "    class_labels = []\n",
        "    for line in lines:\n",
        "        line_class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "        line_class_id = int(line_class_id)\n",
        "\n",
        "        # 증강 대상 클래스만 추가\n",
        "        if line_class_id == class_id:\n",
        "            bboxes.append([x_center, y_center, width, height])\n",
        "            class_labels.append(line_class_id)\n",
        "\n",
        "    # 증강할 클래스가 포함된 경우에만 진행\n",
        "    if bboxes:\n",
        "        print(f\"[진행중] '{image_path}'에서 클래스 {class_id} 증강 시작... (목표: {target_count}회)\")\n",
        "        for i in range(target_count):\n",
        "            try:\n",
        "                augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "                augmented_image = augmented['image']\n",
        "                augmented_bboxes = augmented['bboxes']\n",
        "                augmented_classes = augmented['class_labels']\n",
        "\n",
        "                # 고유한 파일 이름 생성\n",
        "                unique_id = uuid.uuid4().hex[:8]\n",
        "                output_image_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_{unique_id}.jpg\")\n",
        "                output_label_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(label_path))[0]}_{unique_id}.txt\")\n",
        "\n",
        "                # 증강된 이미지 저장\n",
        "                cv2.imwrite(output_image_path, augmented_image)\n",
        "\n",
        "                # 증강된 라벨 저장\n",
        "                with open(output_label_path, 'w') as label_file:\n",
        "                    for aug_class_id, bbox in zip(augmented_classes, augmented_bboxes):\n",
        "                        label_file.write(f\"{aug_class_id} {' '.join(map(str, bbox))}\\n\")\n",
        "\n",
        "                print(f\"[완료] '{output_image_path}' 및 라벨 저장 완료.\")\n",
        "            except KeyError as ke:\n",
        "                print(f\"[오류] KeyError 발생: {ke}, 클래스 라벨: {class_labels}, 바운딩 박스: {bboxes}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[오류] 증강 중 다른 오류 발생: {type(e).__name__}, {e}\")\n",
        "\n",
        "# 멀티스레드 병렬 처리 함수\n",
        "def process_parallel():\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for label_file in os.listdir(label_dir):\n",
        "            if label_file.endswith('.txt'):\n",
        "                image_file = label_file.replace('.txt', '.jpg')\n",
        "                image_path = os.path.join(image_dir, image_file)\n",
        "                label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "                # 라벨 파일 내용에서 증강 대상 클래스가 있는지 확인\n",
        "                with open(label_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "                    has_augment_class = False\n",
        "                    for line in lines:\n",
        "                        line_class_id = int(line.strip().split()[0])\n",
        "                        if line_class_id in augment_classes:\n",
        "                            has_augment_class = True\n",
        "                            break\n",
        "\n",
        "                # 증강 대상 클래스가 포함된 경우만 증강 진행\n",
        "                if has_augment_class:\n",
        "                    print(f\"[진행중] '{label_file}' 파일에서 증강 대상 클래스 확인됨.\")\n",
        "                    for class_id, target_count in augment_classes.items():\n",
        "                        # 각 증강 대상 클래스별로 별도의 증강 수행\n",
        "                        futures.append(executor.submit(augment_data, image_path, label_path, output_dir, class_id, target_count))\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                future.result()\n",
        "            except Exception as e:\n",
        "                print(f\"[오류] Error 발생: {type(e).__name__}, {e}\")\n",
        "\n",
        "process_parallel()\n",
        "print(\"모든 데이터 증강이 완료되었습니다!\")\n"
      ],
      "metadata": {
        "id": "YIaEkzXwz_DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "label_dir = '/content/drive/MyDrive/yolo_training_A1/train'\n",
        "\n",
        "# 파일 목록을 출력\n",
        "try:\n",
        "    files = os.listdir(label_dir)\n",
        "    print(files)\n",
        "except OSError as e:\n",
        "    print(f\"Error accessing the directory: {e}\")\n"
      ],
      "metadata": {
        "id": "UvIomC4VtUJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# YOLO 형식의 라벨이 있는 디렉토리 설정\n",
        "label_dir = '/content/drive/MyDrive/yolo_training_A1/Merged_Data_A1'\n",
        "\n",
        "# 클래스별 객체 수 저장 딕셔너리\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# 라벨 파일에서 클래스 ID 읽어서 카운팅하는 함수\n",
        "def process_label_file(label_file):\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    local_class_counts = defaultdict(int)\n",
        "\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])  # 클래스 ID는 라벨 파일의 첫 번째 값\n",
        "                local_class_counts[class_id] += 1\n",
        "    return local_class_counts\n",
        "\n",
        "# 병렬로 파일 처리\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # 멀티스레드로 파일 처리\n",
        "    results = executor.map(process_label_file, label_files)\n",
        "\n",
        "    # 결과 합산\n",
        "    for local_class_counts in results:\n",
        "        for class_id, count in local_class_counts.items():\n",
        "            class_counts[class_id] += count\n",
        "\n",
        "# 클래스별 개수 출력\n",
        "for class_id, count in class_counts.items():\n",
        "    print(f\"클래스 ID {class_id}의 객체 수: {count}\")\n"
      ],
      "metadata": {
        "id": "d308QjMfrtGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 원본 디렉토리 경로\n",
        "augmented_dir = '/content/drive/MyDrive/yolo_training_A1/Augmented_Output_Data_A1'\n",
        "filtered_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_train'\n",
        "\n",
        "# 새로운 병합 디렉토리 경로\n",
        "merged_dir = '/content/drive/MyDrive/yolo_training_A1/Merged_Data_A1'\n",
        "os.makedirs(merged_dir, exist_ok=True)\n",
        "\n",
        "# 디렉토리에서 파일 복사하는 함수\n",
        "def copy_files_to_merged_dir(src_dir, dst_dir):\n",
        "    for file_name in os.listdir(src_dir):\n",
        "        src_path = os.path.join(src_dir, file_name)\n",
        "        dst_path = os.path.join(dst_dir, file_name)\n",
        "\n",
        "        # 파일이 이미 존재하는지 확인하고, 없다면 복사\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            print(f\"[복사 완료] '{src_path}' -> '{dst_path}'\")\n",
        "        else:\n",
        "            print(f\"[중복 파일] '{file_name}'은 이미 '{dst_dir}'에 존재하여 건너뜁니다.\")\n",
        "\n",
        "# 각 원본 디렉토리에서 파일을 병합 디렉토리로 복사\n",
        "print(\"증강 데이터 파일 복사 중...\")\n",
        "copy_files_to_merged_dir(augmented_dir, merged_dir)\n",
        "\n",
        "print(\"필터링된 데이터 파일 복사 중...\")\n",
        "copy_files_to_merged_dir(filtered_dir, merged_dir)\n",
        "\n",
        "print(\"모든 파일이 병합 디렉토리에 복사되었습니다.\")\n"
      ],
      "metadata": {
        "id": "jUal27uuuV4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0Zxl3EIR5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 두 개의 폴더 경로 설정\n",
        "# LabeledData_path = '/content/drive/MyDrive/01-1.정식개방데이터/Output_LabeledData_A1'\n",
        "# SourceData_path = '/content/drive/MyDrive/01-1.정식개방데이터/Output_SourceData_A1'\n",
        "\n",
        "# # 폴더 내 파일 개수 세기\n",
        "# LabeledData_count = len([name for name in os.listdir(LabeledData_path) if os.path.isfile(os.path.join(LabeledData_path, name))])\n",
        "# SourceData_count = len([name for name in os.listdir(SourceData_path) if os.path.isfile(os.path.join(SourceData_path, name))])\n",
        "\n",
        "# # 결과 출력\n",
        "# print(f\"라벨링데이터의 파일 개수: {LabeledData_count}\")\n",
        "# print(f\"원천데이터의 파일 개수: {SourceData_count}\")"
      ],
      "metadata": {
        "id": "R30M9SVgGk7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "\n",
        "# # 이미지와 라벨 파일 경로 설정 (구글 드라이브 내 경로로 설정)\n",
        "\n",
        "# image_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Output_SourceData_A1'  # 이미지 저장 경로\n",
        "# label_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Output_LabeledData_A1'  # 라벨 파일 저장 경로\n",
        "# # 이미지와 라벨 파일 리스트 얻기\n",
        "# image_files = set([os.path.splitext(f)[0] for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "# label_files = set([os.path.splitext(f)[0] for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
        "\n",
        "# # 이미지와 라벨 모두 있는 파일 리스트 찾기\n",
        "# valid_files = image_files.intersection(label_files)\n",
        "\n",
        "# # 이미지나 라벨만 있는 파일 리스트\n",
        "# only_image_files = image_files - valid_files\n",
        "# only_label_files = label_files - valid_files\n",
        "\n",
        "# # 이미지나 라벨 중 하나만 있는 파일 삭제 (필요시)\n",
        "# for file in only_image_files:\n",
        "#     os.remove(os.path.join(image_dir, file + '.jpg'))\n",
        "\n",
        "# for file in only_label_files:\n",
        "#     os.remove(os.path.join(label_dir, file + '.txt'))\n",
        "\n",
        "# print(f\"총 {len(valid_files)}개의 유효한 이미지와 라벨 파일이 있습니다.\")"
      ],
      "metadata": {
        "id": "YXKpIELxE_fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 갯수 확인\n",
        "import os\n",
        "\n",
        "# 이건 하나의 폴더에 있을때 거기서 갯수 확인해보는거\n",
        "# 두 개의 폴더가 아닌 하나의 폴더 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/yolo_training_A1/Merged_Data_A1'\n",
        "\n",
        "# 이미지와 라벨 파일 구분하여 리스트 생성\n",
        "image_files = [name for name in os.listdir(data_dir) if name.endswith('.jpg')]\n",
        "label_files = [name for name in os.listdir(data_dir) if name.endswith('.txt')]\n",
        "\n",
        "# 이미지 파일과 라벨 파일 개수 확인\n",
        "image_count = len(image_files)\n",
        "label_count = len(label_files)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"이미지 파일 개수: {image_count}\")\n",
        "print(f\"라벨 파일 개수: {label_count}\")\n"
      ],
      "metadata": {
        "id": "kgVdNWLVmB7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지와 라벨 매칭 확인\n",
        "\n",
        "# 이것도 하나의 폴더에 있을때 손실난 부분 맞추는거\n",
        "# 이미지와 라벨 파일 리스트 얻기 (같은 폴더 내에서 가져옴)\n",
        "image_files = set([os.path.splitext(f)[0] for f in os.listdir(data_dir) if f.endswith('.jpg')])\n",
        "label_files = set([os.path.splitext(f)[0] for f in os.listdir(data_dir) if f.endswith('.txt')])\n",
        "\n",
        "# 이미지와 라벨 모두 있는 파일 리스트 찾기\n",
        "valid_files = image_files.intersection(label_files)\n",
        "\n",
        "# 이미지나 라벨만 있는 파일 리스트\n",
        "only_image_files = image_files - valid_files\n",
        "only_label_files = label_files - valid_files\n",
        "\n",
        "# 이미지나 라벨 중 하나만 있는 파일 삭제 (필요시)\n",
        "# for file in only_image_files:\n",
        "#     os.remove(os.path.join(data_dir, file + '.jpg'))\n",
        "\n",
        "# for file in only_label_files:\n",
        "#     os.remove(os.path.join(data_dir, file + '.txt'))\n",
        "\n",
        "print(f\"총 {len(valid_files)}개의 유효한 이미지와 라벨 파일이 있습니다.\")\n"
      ],
      "metadata": {
        "id": "zRh5FuBcmGNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# 원본 검증 데이터 경로 및 새로운 검증 데이터 경로 정의\n",
        "original_val_dir = '/content/drive/MyDrive/yolo_training_A1/filtered_val'  # 원본 검증 데이터 경로\n",
        "new_val_dir = '/content/drive/MyDrive/yolo_training_A1/augmented_val'  # 새로운 검증 데이터 경로\n",
        "\n",
        "# 새로운 검증 데이터 폴더 생성\n",
        "os.makedirs(new_val_dir, exist_ok=True)\n",
        "\n",
        "# 검증 데이터에서 클래스 0, 3만 포함된 데이터를 추출하는 함수 정의\n",
        "def process_file(filename):\n",
        "    if filename.endswith('.jpg'):\n",
        "        # 이미지 파일 경로 설정\n",
        "        img_path = os.path.join(original_val_dir, filename)\n",
        "        label_path = img_path.replace('.jpg', '.txt')\n",
        "\n",
        "        # 라벨 파일이 존재하지 않는 경우 건너뜀\n",
        "        if not os.path.exists(label_path):\n",
        "            return\n",
        "\n",
        "        # 라벨 파일에서 클래스 0, 3 정보 추출\n",
        "        new_label_lines = []\n",
        "        with open(label_path, 'r') as label_file:\n",
        "            lines = label_file.readlines()\n",
        "            for line in lines:\n",
        "                parts = line.split()  # YOLO 형식의 각 줄을 공백으로 분할\n",
        "                class_id = int(parts[0])  # 첫 번째 요소가 클래스 ID\n",
        "                if class_id in [0, 3]:  # 클래스 0 또는 3만 남김\n",
        "                    new_label_lines.append(line)\n",
        "\n",
        "        # 클래스 0, 3만 포함된 데이터가 존재하는 경우에만 이미지와 수정된 라벨 파일을 복사\n",
        "        if new_label_lines:\n",
        "            # 이미지 파일 복사\n",
        "            shutil.copy(img_path, os.path.join(new_val_dir, filename))\n",
        "\n",
        "            # 수정된 라벨 파일 생성\n",
        "            new_label_path = os.path.join(new_val_dir, os.path.basename(label_path))\n",
        "            with open(new_label_path, 'w') as new_label_file:\n",
        "                new_label_file.writelines(new_label_lines)\n",
        "\n",
        "# 멀티스레딩을 통해 데이터 처리\n",
        "with ThreadPoolExecutor(max_workers=8) as executor:  # 최대 8개의 스레드 사용\n",
        "    executor.map(process_file, os.listdir(original_val_dir))\n"
      ],
      "metadata": {
        "id": "N8tRmnPsRydi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 갯수 확인\n",
        "import os\n",
        "\n",
        "# 이건 하나의 폴더에 있을때 거기서 갯수 확인해보는거\n",
        "# 두 개의 폴더가 아닌 하나의 폴더 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/yolo_training_A1/augmented_val'\n",
        "\n",
        "# 이미지와 라벨 파일 구분하여 리스트 생성\n",
        "image_files = [name for name in os.listdir(data_dir) if name.endswith('.jpg')]\n",
        "label_files = [name for name in os.listdir(data_dir) if name.endswith('.txt')]\n",
        "\n",
        "# 이미지 파일과 라벨 파일 개수 확인\n",
        "image_count = len(image_files)\n",
        "label_count = len(label_files)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"이미지 파일 개수: {image_count}\")\n",
        "print(f\"라벨 파일 개수: {label_count}\")"
      ],
      "metadata": {
        "id": "Dr1_7XlBaw-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지와 라벨 매칭 확인\n",
        "\n",
        "# 이것도 하나의 폴더에 있을때 손실난 부분 맞추는거\n",
        "# 이미지와 라벨 파일 리스트 얻기 (같은 폴더 내에서 가져옴)\n",
        "image_files = set([os.path.splitext(f)[0] for f in os.listdir(data_dir) if f.endswith('.jpg')])\n",
        "label_files = set([os.path.splitext(f)[0] for f in os.listdir(data_dir) if f.endswith('.txt')])\n",
        "\n",
        "# 이미지와 라벨 모두 있는 파일 리스트 찾기\n",
        "valid_files = image_files.intersection(label_files)\n",
        "\n",
        "# 이미지나 라벨만 있는 파일 리스트\n",
        "only_image_files = image_files - valid_files\n",
        "only_label_files = label_files - valid_files\n",
        "\n",
        "# 이미지나 라벨 중 하나만 있는 파일 삭제 (필요시)\n",
        "# for file in only_image_files:\n",
        "#     os.remove(os.path.join(data_dir, file + '.jpg'))\n",
        "\n",
        "# for file in only_label_files:\n",
        "#     os.remove(os.path.join(data_dir, file + '.txt'))\n",
        "\n",
        "print(f\"총 {len(valid_files)}개의 유효한 이미지와 라벨 파일이 있습니다.\")"
      ],
      "metadata": {
        "id": "6VBL1p5idCGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# YOLO 형식의 라벨이 있는 디렉토리 설정\n",
        "label_dir = '/content/drive/MyDrive/yolo_training_A1/augmented_val'\n",
        "\n",
        "# 클래스별 객체 수 저장 딕셔너리\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# 라벨 파일에서 클래스 ID 읽어서 카운팅하는 함수\n",
        "def process_label_file(label_file):\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    local_class_counts = defaultdict(int)\n",
        "\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])  # 클래스 ID는 라벨 파일의 첫 번째 값\n",
        "                local_class_counts[class_id] += 1\n",
        "    return local_class_counts\n",
        "\n",
        "# 병렬로 파일 처리\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # 멀티스레드로 파일 처리\n",
        "    results = executor.map(process_label_file, label_files)\n",
        "\n",
        "    # 결과 합산\n",
        "    for local_class_counts in results:\n",
        "        for class_id, count in local_class_counts.items():\n",
        "            class_counts[class_id] += count\n",
        "\n",
        "# 클래스별 개수 출력\n",
        "for class_id, count in class_counts.items():\n",
        "    print(f\"클래스 ID {class_id}의 객체 수: {count}\")"
      ],
      "metadata": {
        "id": "Ss51rVZZdHVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cp /content/drive/MyDrive/yolo_training_A1/filtered_train-20241109T202844Z-001.zip /content/\n"
      ],
      "metadata": {
        "id": "rFgcklqUFwln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import concurrent.futures\n",
        "import os\n",
        "\n",
        "# 압축 해제할 경로 설정\n",
        "extract_path = '/content/filtered_train_data'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# ZIP 파일 목록\n",
        "zip_files = ['/content/filtered_train-20241109T202844Z-001.zip']\n",
        "\n",
        "# ZIP 파일을 압축 해제하는 함수 정의\n",
        "def extract_zip(zip_file):\n",
        "    try:\n",
        "        sub_extract_path = os.path.join(extract_path, os.path.basename(zip_file).replace('.zip', ''))\n",
        "        os.makedirs(sub_extract_path, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f'{zip_file} 압축 해제 완료')\n",
        "    except Exception as e:\n",
        "        print(f'{zip_file} 압축 해제 중 오류 발생: {e}')\n",
        "\n",
        "# 멀티스레딩을 사용하여 ZIP 파일을 병렬로 압축 해제\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    executor.map(extract_zip, zip_files)\n",
        "\n",
        "print(\"모든 ZIP 파일이 멀티스레드 방식으로 한 폴더에 압축 해제되었습니다.\")\n"
      ],
      "metadata": {
        "id": "47mgeG2AFw6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from collections import Counter\n",
        "\n",
        "# 원본 데이터 경로 및 새로운 데이터 경로 정의\n",
        "original_dir = '/content/filtered_train_data'  # 학습 데이터 폴더\n",
        "train_output_dir = '/content/drive/MyDrive/filtered_train_balanced'  # 학습 데이터 출력 폴더\n",
        "val_output_dir = '/content/drive/MyDrive/filtered_val_balanced'  # 검증 데이터 출력 폴더\n",
        "\n",
        "# 새로운 폴더 생성\n",
        "os.makedirs(train_output_dir, exist_ok=True)\n",
        "os.makedirs(val_output_dir, exist_ok=True)\n",
        "\n",
        "# 각 이미지의 클래스 레이블을 저장하기 위한 리스트 초기화\n",
        "image_paths = []\n",
        "class_labels = []\n",
        "\n",
        "# 데이터셋에서 각 이미지에 포함된 클래스 정보를 확인하고 저장\n",
        "for root, dirs, files in os.walk(original_dir):\n",
        "    for filename in files:\n",
        "        if filename.endswith('.txt'):\n",
        "            label_path = os.path.join(root, filename)\n",
        "            with open(label_path, 'r') as label_file:\n",
        "                lines = label_file.readlines()\n",
        "                classes_in_image = set()\n",
        "                for line in lines:\n",
        "                    class_id = int(line.split()[0])  # 클래스 ID 추출\n",
        "                    classes_in_image.add(class_id)\n",
        "\n",
        "                # 이미지 파일과 해당 클래스 레이블 정보 저장\n",
        "                image_filename = filename.replace('.txt', '.jpg')\n",
        "                image_path = os.path.join(root, image_filename)\n",
        "                image_paths.append(image_path)\n",
        "\n",
        "                # 클래스 조합을 문자열로 변환하여 고유한 레이블로 사용\n",
        "                class_combination = '-'.join(map(str, sorted(classes_in_image)))\n",
        "                class_labels.append(class_combination)\n",
        "\n",
        "# 클래스 조합 빈도수 확인\n",
        "class_counts = Counter(class_labels)\n",
        "\n",
        "# 빈도수가 2개 미만인 클래스 조합 필터링 방지\n",
        "filtered_image_paths = image_paths\n",
        "filtered_class_labels = class_labels\n",
        "\n",
        "# 학습 데이터와 검증 데이터 나누기 (8:2 비율), 클래스 비율을 유지\n",
        "if len(filtered_class_labels) > 1:  # 클래스 레이블이 충분히 존재하는 경우에만 분할\n",
        "    try:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            filtered_image_paths, filtered_class_labels, test_size=0.2, random_state=42, stratify=filtered_class_labels\n",
        "        )\n",
        "    except ValueError:\n",
        "        # 클래스 레이블이 충분하지 않은 경우, 데이터를 임의로 나누되 데이터 손실을 방지\n",
        "        split_index = int(len(filtered_image_paths) * 0.8)\n",
        "        X_train, X_val = filtered_image_paths[:split_index], filtered_image_paths[split_index:]\n",
        "        y_train, y_val = filtered_class_labels[:split_index], filtered_class_labels[split_index:]\n",
        "else:\n",
        "    raise ValueError(\"클래스 레이블이 충분하지 않습니다. 데이터셋을 확인하세요.\")\n",
        "\n",
        "# 멀티스레딩을 사용하여 파일 복사 작업 수행\n",
        "def copy_files(img_filename, output_dir):\n",
        "    img_path = img_filename  # img_filename은 이미 전체 경로를 포함하고 있음\n",
        "    label_path = img_path.replace('.jpg', '.txt')\n",
        "\n",
        "    # 이미지 파일 복사\n",
        "    shutil.copy(img_path, os.path.join(output_dir, os.path.basename(img_filename)))\n",
        "    # 라벨 파일 복사\n",
        "    shutil.copy(label_path, os.path.join(output_dir, os.path.basename(label_path)))\n",
        "\n",
        "# 멀티스레드 실행 설정 (최대 8개의 스레드 사용)\n",
        "with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "    # 학습 데이터 복사\n",
        "    executor.map(lambda img: copy_files(img, train_output_dir), X_train)\n",
        "    # 검증 데이터 복사\n",
        "    executor.map(lambda img: copy_files(img, val_output_dir), X_val)\n"
      ],
      "metadata": {
        "id": "sVwkmFkVgTNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# YOLO 형식의 라벨이 있는 디렉토리 설정\n",
        "label_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Output_Data_00/A5/train/A5'\n",
        "\n",
        "# 클래스별 객체 수 저장 딕셔너리\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# 라벨 파일에서 클래스 ID 읽어서 카운팅하는 함수\n",
        "def process_label_file(label_file):\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    local_class_counts = defaultdict(int)\n",
        "\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])  # 클래스 ID는 라벨 파일의 첫 번째 값\n",
        "                local_class_counts[class_id] += 1\n",
        "    return local_class_counts\n",
        "\n",
        "# 병렬로 파일 처리\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # 멀티스레드로 파일 처리\n",
        "    results = executor.map(process_label_file, label_files)\n",
        "\n",
        "    # 결과 합산\n",
        "    for local_class_counts in results:\n",
        "        for class_id, count in local_class_counts.items():\n",
        "            class_counts[class_id] += count\n",
        "\n",
        "# 클래스별 개수 출력\n",
        "for class_id, count in class_counts.items():\n",
        "    print(f\"클래스 ID {class_id}의 객체 수: {count}\")"
      ],
      "metadata": {
        "id": "R6RsjRtSVh7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 갯수 확인\n",
        "import os\n",
        "\n",
        "# 이건 하나의 폴더에 있을때 거기서 갯수 확인해보는거\n",
        "# 두 개의 폴더가 아닌 하나의 폴더 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/01-1.정식개방데이터/Output_Data_00/A5/train/A5'\n",
        "\n",
        "# 이미지와 라벨 파일 구분하여 리스트 생성\n",
        "image_files = [name for name in os.listdir(data_dir) if name.endswith('.jpg')]\n",
        "label_files = [name for name in os.listdir(data_dir) if name.endswith('.txt')]\n",
        "\n",
        "# 이미지 파일과 라벨 파일 개수 확인\n",
        "image_count = len(image_files)\n",
        "label_count = len(label_files)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"이미지 파일 개수: {image_count}\")\n",
        "print(f\"라벨 파일 개수: {label_count}\")"
      ],
      "metadata": {
        "id": "3i5PhTXtWM0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 폴더 압축\n",
        "!zip -r /content/filtered_train_balanced.zip /content/drive/MyDrive/filtered_train_balanced\n",
        "\n",
        "# 두 번째 폴더 압축\n",
        "!zip -r /content/filtered_val_balanced.zip /content/drive/MyDrive/filtered_val_balanced"
      ],
      "metadata": {
        "id": "VdwT_rldXMuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import concurrent.futures\n",
        "import os\n",
        "\n",
        "# 압축 해제할 경로 설정\n",
        "extract_path = '/content/filtered_train_balanced'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# ZIP 파일 목록\n",
        "zip_files = ['/content/filtered_train_balanced.zip']\n",
        "\n",
        "# ZIP 파일을 압축 해제하는 함수 정의\n",
        "def extract_zip(zip_file):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f'{zip_file} 압축 해제 완료')\n",
        "    except Exception as e:\n",
        "        print(f'{zip_file} 압축 해제 중 오류 발생: {e}')\n",
        "\n",
        "# 멀티스레딩을 사용하여 ZIP 파일을 병렬로 압축 해제\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    executor.map(extract_zip, zip_files)\n",
        "\n",
        "print(\"모든 ZIP 파일이 멀티스레드 방식으로 한 폴더에 압축 해제되었습니다.\")\n"
      ],
      "metadata": {
        "id": "aFinDzCGFRfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 원본 데이터셋 경로와 새 폴더 경로 설정\n",
        "original_dataset_path = '/content/filtered_train_balanced/content/drive/MyDrive/filtered_train_balanced'  # 이미지와 라벨 데이터가 같이 있는 폴더\n",
        "new_dataset_path = '/content/new_train_A1'  # 클래스 3을 포함하는 데이터가 저장될 폴더\n",
        "\n",
        "# 새 폴더 생성\n",
        "os.makedirs(new_dataset_path, exist_ok=True)\n",
        "\n",
        "# 라벨 데이터가 있는 경로 설정\n",
        "label_files_path = [file for file in os.listdir(original_dataset_path) if file.endswith('.txt')]\n",
        "\n",
        "# 클래스 3을 포함하는 데이터 필터링 함수 정의\n",
        "def filter_and_copy(label_file):\n",
        "    label_file_path = os.path.join(original_dataset_path, label_file)\n",
        "    with open(label_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # 클래스 3을 포함하는지 확인\n",
        "    contains_class_3 = any(line.split()[0] == '3' for line in lines)\n",
        "\n",
        "    if contains_class_3:\n",
        "        # 해당 라벨 파일을 새로운 폴더로 복사\n",
        "        shutil.copy(label_file_path, os.path.join(new_dataset_path, label_file))\n",
        "\n",
        "        # 동일한 이름의 이미지 파일도 복사\n",
        "        image_file = label_file.replace('.txt', '.jpg')\n",
        "        image_file_path = os.path.join(original_dataset_path, image_file)\n",
        "        if os.path.exists(image_file_path):\n",
        "            shutil.copy(image_file_path, os.path.join(new_dataset_path, image_file))\n",
        "\n",
        "# 멀티스레드 방식으로 클래스 3을 포함하는 데이터 필터링 및 복사\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    list(tqdm(executor.map(filter_and_copy, label_files_path), total=len(label_files_path), desc=\"Filtering labels containing class 3\"))\n",
        "\n",
        "print(\"데이터 필터링 완료: 클래스 3을 포함하는 데이터들만 새 폴더에 복사되었습니다.\")\n"
      ],
      "metadata": {
        "id": "TV5tR_vmuINh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmohxCIBKWYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# YOLO 형식의 라벨이 있는 디렉토리 설정\n",
        "label_dir = '/content/new_train_A1'\n",
        "\n",
        "# 클래스별 객체 수 저장 딕셔너리\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# 라벨 파일에서 클래스 ID 읽어서 카운팅하는 함수\n",
        "def process_label_file(label_file):\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    local_class_counts = defaultdict(int)\n",
        "\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])  # 클래스 ID는 라벨 파일의 첫 번째 값\n",
        "                local_class_counts[class_id] += 1\n",
        "    return local_class_counts\n",
        "\n",
        "# 병렬로 파일 처리\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # 멀티스레드로 파일 처리\n",
        "    results = executor.map(process_label_file, label_files)\n",
        "\n",
        "    # 결과 합산\n",
        "    for local_class_counts in results:\n",
        "        for class_id, count in local_class_counts.items():\n",
        "            class_counts[class_id] += count\n",
        "\n",
        "# 클래스별 개수 출력\n",
        "for class_id, count in class_counts.items():\n",
        "    print(f\"클래스 ID {class_id}의 객체 수: {count}\")"
      ],
      "metadata": {
        "id": "QTICT1ATKHs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 원본 데이터셋 경로와 새 폴더 경로 설정\n",
        "original_dataset_path = '/content/filtered_train_balanced/content/drive/MyDrive/filtered_train_balanced'  # 이미지와 라벨 데이터가 같이 있는 폴더\n",
        "new_dataset_path = '/content/new_train_A1_with_0'  # 클래스 3을 포함하는 데이터가 저장될 폴더\n",
        "\n",
        "# 새 폴더 생성\n",
        "os.makedirs(new_dataset_path, exist_ok=True)\n",
        "\n",
        "# 라벨 데이터가 있는 경로 설정\n",
        "label_files_path = [file for file in os.listdir(original_dataset_path) if file.endswith('.txt')]\n",
        "\n",
        "# 클래스 3을 포함하는 데이터 필터링 함수 정의\n",
        "def filter_and_copy(label_file):\n",
        "    label_file_path = os.path.join(original_dataset_path, label_file)\n",
        "    with open(label_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # 클래스 3을 포함하는지 확인\n",
        "    contains_class_3 = any(line.split()[0] == '0' for line in lines)\n",
        "\n",
        "    if contains_class_3:\n",
        "        # 해당 라벨 파일을 새로운 폴더로 복사\n",
        "        shutil.copy(label_file_path, os.path.join(new_dataset_path, label_file))\n",
        "\n",
        "        # 동일한 이름의 이미지 파일도 복사\n",
        "        image_file = label_file.replace('.txt', '.jpg')\n",
        "        image_file_path = os.path.join(original_dataset_path, image_file)\n",
        "        if os.path.exists(image_file_path):\n",
        "            shutil.copy(image_file_path, os.path.join(new_dataset_path, image_file))\n",
        "\n",
        "# 멀티스레드 방식으로 클래스 3을 포함하는 데이터 필터링 및 복사\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    list(tqdm(executor.map(filter_and_copy, label_files_path), total=len(label_files_path), desc=\"Filtering labels containing class 3\"))\n",
        "\n",
        "print(\"데이터 필터링 완료: 클래스 3을 포함하는 데이터들만 새 폴더에 복사되었습니다.\")\n"
      ],
      "metadata": {
        "id": "gF6ZGND5KXd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# YOLO 형식의 라벨이 있는 디렉토리 설정\n",
        "label_dir = '/content/new_train_A1_with_0'\n",
        "\n",
        "# 클래스별 객체 수 저장 딕셔너리\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# 라벨 파일에서 클래스 ID 읽어서 카운팅하는 함수\n",
        "def process_label_file(label_file):\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    local_class_counts = defaultdict(int)\n",
        "\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])  # 클래스 ID는 라벨 파일의 첫 번째 값\n",
        "                local_class_counts[class_id] += 1\n",
        "    return local_class_counts\n",
        "\n",
        "# 병렬로 파일 처리\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # 멀티스레드로 파일 처리\n",
        "    results = executor.map(process_label_file, label_files)\n",
        "\n",
        "    # 결과 합산\n",
        "    for local_class_counts in results:\n",
        "        for class_id, count in local_class_counts.items():\n",
        "            class_counts[class_id] += count\n",
        "\n",
        "# 클래스별 개수 출력\n",
        "for class_id, count in class_counts.items():\n",
        "    print(f\"클래스 ID {class_id}의 객체 수: {count}\")"
      ],
      "metadata": {
        "id": "4Mp-iRT2Kejh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import concurrent.futures\n",
        "import os\n",
        "\n",
        "# 압축 해제할 경로 설정\n",
        "extract_path = '/content/filtered_val_balanced'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# ZIP 파일 목록\n",
        "zip_files = ['/content/filtered_val_balanced.zip']\n",
        "\n",
        "# ZIP 파일을 압축 해제하는 함수 정의\n",
        "def extract_zip(zip_file):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f'{zip_file} 압축 해제 완료')\n",
        "    except Exception as e:\n",
        "        print(f'{zip_file} 압축 해제 중 오류 발생: {e}')\n",
        "\n",
        "# 멀티스레딩을 사용하여 ZIP 파일을 병렬로 압축 해제\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    executor.map(extract_zip, zip_files)\n",
        "\n",
        "print(\"모든 ZIP 파일이 멀티스레드 방식으로 한 폴더에 압축 해제되었습니다.\")\n"
      ],
      "metadata": {
        "id": "Ti0AxYhbLT16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 원본 데이터셋 경로와 새 폴더 경로 설정\n",
        "original_dataset_path = '/content/filtered_val_balanced/content/drive/MyDrive/filtered_val_balanced'  # 이미지와 라벨 데이터가 같이 있는 폴더\n",
        "new_dataset_path = '/content/new_val_A1'  # 클래스 3을 포함하는 데이터가 저장될 폴더\n",
        "\n",
        "# 새 폴더 생성\n",
        "os.makedirs(new_dataset_path, exist_ok=True)\n",
        "\n",
        "# 라벨 데이터가 있는 경로 설정\n",
        "label_files_path = [file for file in os.listdir(original_dataset_path) if file.endswith('.txt')]\n",
        "\n",
        "# 클래스 3을 포함하는 데이터 필터링 함수 정의\n",
        "def filter_and_copy(label_file):\n",
        "    label_file_path = os.path.join(original_dataset_path, label_file)\n",
        "    with open(label_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # 클래스 3을 포함하는지 확인\n",
        "    contains_class_3 = any(line.split()[0] == '3' for line in lines)\n",
        "\n",
        "    if contains_class_3:\n",
        "        # 해당 라벨 파일을 새로운 폴더로 복사\n",
        "        shutil.copy(label_file_path, os.path.join(new_dataset_path, label_file))\n",
        "\n",
        "        # 동일한 이름의 이미지 파일도 복사\n",
        "        image_file = label_file.replace('.txt', '.jpg')\n",
        "        image_file_path = os.path.join(original_dataset_path, image_file)\n",
        "        if os.path.exists(image_file_path):\n",
        "            shutil.copy(image_file_path, os.path.join(new_dataset_path, image_file))\n",
        "\n",
        "# 멀티스레드 방식으로 클래스 3을 포함하는 데이터 필터링 및 복사\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    list(tqdm(executor.map(filter_and_copy, label_files_path), total=len(label_files_path), desc=\"Filtering labels containing class 3\"))\n",
        "\n",
        "print(\"데이터 필터링 완료: 클래스 3을 포함하는 데이터들만 새 폴더에 복사되었습니다.\")\n"
      ],
      "metadata": {
        "id": "kExNyo53LiTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# YOLO 형식의 라벨이 있는 디렉토리 설정\n",
        "label_dir = '/content/new_val_A1'\n",
        "\n",
        "# 클래스별 객체 수 저장 딕셔너리\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# 라벨 파일에서 클래스 ID 읽어서 카운팅하는 함수\n",
        "def process_label_file(label_file):\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    local_class_counts = defaultdict(int)\n",
        "\n",
        "    if label_file.endswith('.txt'):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])  # 클래스 ID는 라벨 파일의 첫 번째 값\n",
        "                local_class_counts[class_id] += 1\n",
        "    return local_class_counts\n",
        "\n",
        "# 병렬로 파일 처리\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # 멀티스레드로 파일 처리\n",
        "    results = executor.map(process_label_file, label_files)\n",
        "\n",
        "    # 결과 합산\n",
        "    for local_class_counts in results:\n",
        "        for class_id, count in local_class_counts.items():\n",
        "            class_counts[class_id] += count\n",
        "\n",
        "# 클래스별 개수 출력\n",
        "for class_id, count in class_counts.items():\n",
        "    print(f\"클래스 ID {class_id}의 객체 수: {count}\")"
      ],
      "metadata": {
        "id": "ypOgu67MMI3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 갯수 확인\n",
        "import os\n",
        "\n",
        "# 이건 하나의 폴더에 있을때 거기서 갯수 확인해보는거\n",
        "# 두 개의 폴더가 아닌 하나의 폴더 경로 설정\n",
        "data_dir = '/content/new_val_A1'\n",
        "\n",
        "# 이미지와 라벨 파일 구분하여 리스트 생성\n",
        "image_files = [name for name in os.listdir(data_dir) if name.endswith('.jpg')]\n",
        "label_files = [name for name in os.listdir(data_dir) if name.endswith('.txt')]\n",
        "\n",
        "# 이미지 파일과 라벨 파일 개수 확인\n",
        "image_count = len(image_files)\n",
        "label_count = len(label_files)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"이미지 파일 개수: {image_count}\")\n",
        "print(f\"라벨 파일 개수: {label_count}\")"
      ],
      "metadata": {
        "id": "8gKurZPdMj46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 갯수 확인\n",
        "import os\n",
        "\n",
        "# 이건 하나의 폴더에 있을때 거기서 갯수 확인해보는거\n",
        "# 두 개의 폴더가 아닌 하나의 폴더 경로 설정\n",
        "data_dir = '/content/new_train_A1'\n",
        "\n",
        "# 이미지와 라벨 파일 구분하여 리스트 생성\n",
        "image_files = [name for name in os.listdir(data_dir) if name.endswith('.jpg')]\n",
        "label_files = [name for name in os.listdir(data_dir) if name.endswith('.txt')]\n",
        "\n",
        "# 이미지 파일과 라벨 파일 개수 확인\n",
        "image_count = len(image_files)\n",
        "label_count = len(label_files)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"이미지 파일 개수: {image_count}\")\n",
        "print(f\"라벨 파일 개수: {label_count}\")"
      ],
      "metadata": {
        "id": "h3bjj_10Mspp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r new_val.zip /content/new_val_A1\n",
        "!zip -r new_train.zip /content/new_train_A1\n"
      ],
      "metadata": {
        "id": "B4OQeST_MkFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}